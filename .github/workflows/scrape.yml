name: Scrape and Parse

on:
  schedule:
    - cron: '0 0 * * *' # run once every day at midnight UTC
  workflow_dispatch: # run manually

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.x
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Scrape data
        run: python scrape.py

      - name: Evaluate downloaded file
        run: |
          python evaluate_downloaded.py tmp/$(date +"%Y-%m-%d").csv
        
      - name: Check if files were created
        run: |
          if [[ $(git status --porcelain | grep '^A') ]]; then
            echo "New files were created. Continuing with the workflow."
          else
            echo "No new files were created. Aborting the workflow."
            exit 0
          fi

      - name: Parse raw data
        run: python parse_raw.py data/raw/$(date +"%Y-%m-%d").csv
                
      - name: Copy parsed data to data/parsed/latest
        run: cp data/parsed/$(date +"%Y-%m-%d")/* data/parsed/latest/

      - name: Stage and commit changes in data/raw
        run: |
          git config --global user.email "jens.finnas@gmail.com"
          git config --global user.name "Jens Finn√§s"
          git add data/raw
          git add data/parsed
          git commit -m "Update data/raw"
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}

